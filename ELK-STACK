mkdir newsapp-lab
cd newsapp-lab

# 2ï¸âƒ£ Create subfolders
mkdir backend
mkdir tests
mkdir -p logstash/pipeline
mkdir filebeat
notepad docker-compose.yml

---docker-compose.yml code---
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.2
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.2
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./backend/logs:/usr/share/logstash/app-logs
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - elasticsearch


1) ---next step---
cd backend
npm init -y
npm install express pino
notepad server.js
const express = require('express');
const pino = require('pino');
const fs = require('fs');
const path = require('path');

const app = express();
app.use(express.json());

// Setup logger (writes logs to file)
const logDir = path.join(__dirname, 'logs');
if (!fs.existsSync(logDir)) fs.mkdirSync(logDir);
const logger = pino(pino.destination(path.join(logDir, 'app.log')));

app.get('/', (req, res) => {
  logger.info({ event: 'home_visit', time: new Date().toISOString() });
  res.send('Welcome to the News App ðŸ—žï¸');
});

app.get('/news/:id', (req, res) => {
  logger.info({ event: 'article_view', articleId: req.params.id, time: new Date().toISOString() });
  res.json({ articleId: req.params.id, title: `News ${req.params.id}`, content: 'Lorem ipsum...' });
});

app.listen(4000, () => console.log('Server running on http://localhost:4000'));
--To Run---
node server.js


2)---Automated test---

cd ../tests
npm init -y
npm install --save-dev jest supertest
notepad app.test.js
--code--
const request = require('supertest');

const baseURL = "http://localhost:4000";

test("Home page returns welcome", async () => {
  const res = await request(baseURL).get('/');
  expect(res.text).toContain('Welcome');
});

test("News article returns json", async () => {
  const res = await request(baseURL).get('/news/1');
  expect(res.body.articleId).toBe('1');
});

--To run--
npx jest

---Next Steo---Root folder

cd ..
docker-compose.yml:
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.2
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.2
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - elasticsearch

---Next Step---

Step 5 â€” Logstash Pipeline

Inside logstash/pipeline/, create file logstash.conf:

input {
  file {
    path => "/usr/share/logstash/app-logs/*.log"
    start_position => "beginning"
    codec => "json"
  }
}

filter { }

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "newsapp-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}
---Next step---Upadte docer-compose.yml---

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    networks:
      - elk

  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.0
    container_name: logstash
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./backend/logs:/usr/share/logstash/app-logs
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch
    networks:
      - elk

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - elk

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.15.0
    container_name: filebeat
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - ./backend/logs:/usr/share/filebeat/logs
    depends_on:
      - logstash
    networks:
      - elk

networks:
  elk:
    driver: bridge
---Next step---
docker compose up -d


